{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "\n",
    "REVIEW_URL = \"https://www.amazon.{region}/reviews/{product_id}\"\n",
    "AMAZON_MAPPINGS = {\"uk\": \"co.uk\", \"us\": \"com\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_region(region=\"uk\"):\n",
    "    \"\"\"Return regional amazon web domain suffix\"\"\"\n",
    "    return AMAZON_MAPPINGS.get(region, region)\n",
    "\n",
    "\n",
    "def get_review_page(product_id, region=\"uk\", url=None):\n",
    "    \"\"\"Request the review page url and return a BeautifulSoup instance\"\"\"\n",
    "    region = get_region(region)\n",
    "    r = requests.get(\n",
    "        url or REVIEW_URL.format(region=region, product_id=product_id),\n",
    "        headers={\n",
    "            \"Cache-Control\": \"no-cache\",\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36\",\n",
    "        },\n",
    "    )\n",
    "    if r.ok:\n",
    "        return BeautifulSoup(r.content, features=\"lxml\")\n",
    "    raise Exception(\"unprocessible page\")\n",
    "\n",
    "\n",
    "def extract_review_meta(soup, region=\"uk\"):\n",
    "    \"\"\"Extract review meta information from BeautifulSoup instance\"\"\"\n",
    "    reviews = soup.find_all(\"div\", {\"class\": \"review\"})\n",
    "    reviews_meta = []\n",
    "    for review in reviews:\n",
    "        content = review.find(\"span\", {\"class\": \"review-text-content\"})\n",
    "        review_text = content.get_text().strip()\n",
    "        review_profile, review_star, review_title = \"\", \"\", \"\"\n",
    "        try:\n",
    "            profile = review.find(\"span\", {\"class\": \"a-profile-name\"})\n",
    "            review_profile = profile.get_text().strip()\n",
    "        except Exception as err:\n",
    "            logging.debug(\"error parsing review profile: %s\", str(err))\n",
    "        try:\n",
    "            star = review.find(\"a\", {\"class\": \"a-link-normal\"})\n",
    "            review_star = star.get_text().strip()\n",
    "        except Exception as err:\n",
    "            logging.debug(\"error parsing review star: %s\", str(err))\n",
    "        try:\n",
    "            title = review.find(\"a\", {\"class\": \"review-title\"})\n",
    "            review_title = title.get_text().strip()\n",
    "        except Exception as err:\n",
    "            logging.debug(\"error parsing review title: %s\", str(err))\n",
    "        reviews_meta.append(\n",
    "            {\n",
    "                \"profile\": review_profile,\n",
    "                \"star\": review_star,\n",
    "                \"title\": review_title,\n",
    "                \"text\": review_text,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    link = soup.find(\"li\", {\"class\": \"a-last\"})\n",
    "    if link:\n",
    "        try:\n",
    "            region = get_region(region)\n",
    "            if link.a:\n",
    "                href = link.a.attrs[\"href\"]\n",
    "                url = \"https://www.amazon.{region}{href}\".format(\n",
    "                    region=region, href=href\n",
    "                )\n",
    "                logging.debug(\"crawling next review page: %s\", url)\n",
    "                next_review = get_review_page(None, region=region, url=url)\n",
    "                reviews_meta.extend(extract_review_meta(next_review, region=region))\n",
    "        except Exception as err:\n",
    "            logging.debug(\"error crawling next review page: %s\", str(err))\n",
    "            pass\n",
    "    return reviews_meta\n",
    "\n",
    "\n",
    "def get_reviews_from_product_id(product_id, region=\"uk\"):\n",
    "    \"\"\"Get review text from a product id\"\"\"\n",
    "    try:\n",
    "        soup = get_review_page(product_id, region=region)\n",
    "        return extract_review_meta(soup, region=region)\n",
    "    except Exception as err:\n",
    "        logging.debug(\"error crawling review page: %s\", str(err))\n",
    "        return []\n",
    "\n",
    "\n",
    "def get_reviews_from_product_ids(product_ids=[], region=\"uk\"):\n",
    "    \"\"\"Get all reviews text from a list of product ids\"\"\"\n",
    "    return [\n",
    "        {product_id: get_reviews_from_product_id(product_id, region=region)}\n",
    "        for product_id in product_ids\n",
    "    ]\n",
    "\n",
    "\n",
    "def runner():\n",
    "    \"\"\"Runner entry point accepting system arguments and extract reviews\"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Add some integers.\")\n",
    "    parser.add_argument(\"-r\", \"--region\", type=str, default=\"uk\")\n",
    "    parser.add_argument(\"-l\", \"--log\", type=str, default=\"INFO\")\n",
    "    parser.add_argument(\n",
    "        \"product_ids\", metavar=\"N\", type=str, nargs=\"+\", help=\"list of product ids\"\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    logging.basicConfig(level=getattr(logging, args.log.upper()))\n",
    "    reviews_text = get_reviews_from_product_ids(args.product_ids, args.region)\n",
    "    logging.debug(reviews_text)\n",
    "    return reviews_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    reviews_text = runner()\n",
    "    # you can use this entry point to generate a pretty printed json output.\n",
    "    # simply run with python crawler.py PRODUCT_IDS... --region uk > out.json\n",
    "    print(json.dumps(reviews_text, sort_keys=True, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
